# -*- coding: utf-8 -*-
"""AirBNB_Data_Analysis_and_Price_Prediction_LightGBM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hxky3tHvgubordhVmd94oLtRF4EJoMYA

Airbnb price prediction aims to estimate the optimal price for a rental listing based on various factors, helping hosts maximize their earnings while remaining competitive. This involves analyzing data like location, property type, amenities, and market trends to predict the most suitable price point.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import xgboost as xgb
warnings.filterwarnings('ignore')
import joblib

!unzip -q /content/AirBnbDataset.zip -d /content/

import pandas as pd

# List of (file_path, city_name) tuples
files_info = [
    ('/content/AirBnbDataset/listings_Paris.csv', 'Paris'),
    ('/content/AirBnbDataset/listings_Rome.csv', 'Rome'),
    ('/content/AirBnbDataset/listings_Amsterdam.csv', 'Amsterdam'),
    ('/content/AirBnbDataset/listings_Berlin.csv', 'Berlin'),
    ('/content/AirBnbDataset/listings_Prague.csv', 'Prague'),
    ('/content/AirBnbDataset/listings_Barcelona.csv', 'Barcelona'),
    ('/content/AirBnbDataset/listings_Budapest.csv', 'Budapest'),
    ('/content/AirBnbDataset/listings_Vienna.csv', 'Vienna'),
    ('/content/AirBnbDataset/listings_Athens.csv', 'Athens'),
    ('/content/AirBnbDataset/listings_Istanbul.csv','Istanbul'),
    ('/content/AirBnbDataset/listings_Dublin.csv','Dublin'),
    ('/content/AirBnbDataset/listings_Oslo.csv','Oslo'),
    ('/content/AirBnbDataset/listings_Stockholm.csv','Stockholm'),
    ('/content/AirBnbDataset/listings_copenhagen.csv','Copenhagen'),
    ('/content/AirBnbDataset/listings_Brussels.csv','Brussels'),
]

# Read and append with city column
df_list = []

for file_path, city in files_info:
    df = pd.read_csv(file_path)
    df['city'] = city  # Add city name
    df_list.append(df)

# Combine all
df = pd.concat(df_list, ignore_index=True)

df.info()

df.describe()

# Statistical Testing Libraries
from scipy import stats
from scipy.stats import (
    chi2_contingency, shapiro, anderson, jarque_bera,
    f_oneway, kruskal, mannwhitneyu,
    pearsonr, spearmanr, kendalltau,
    ttest_ind, ttest_rel, wilcoxon
)
import warnings
warnings.filterwarnings('ignore')

def interpret_pvalue(p_value, test_name, alpha=0.05):
    """Helper function to interpret hypothesis test results"""
    if p_value < alpha:
        return f"‚úÖ {test_name}: SIGNIFICANT (p={p_value:.4f} < {alpha})"
    else:
        return f"‚ùå {test_name}: NOT SIGNIFICANT (p={p_value:.4f} ‚â• {alpha})"

print("üìä Statistical testing environment ready!")

df.head()

"""#Data Preprocessing"""

df.nunique()

df.isna().sum()

df.isna().sum() / df.shape[0] * 100



df.drop(['id', 'host_id', 'host_name', 'last_review','license','neighbourhood_group', 'name'], axis=1 , inplace=True)

df.info()

# HYPOTHESIS TEST: Are missing prices randomly distributed across cities?
print("=== MISSING DATA PATTERN ANALYSIS ===")

df['price_missing'] = df['price'].isnull()
contingency_missing = pd.crosstab(df['city'], df['price_missing'])

chi2, p_missing, dof, expected = chi2_contingency(contingency_missing)
print(interpret_pvalue(p_missing, "Missing Price Pattern Test"))

PRICE_MISSING_SYSTEMATIC = p_missing < 0.05

df.drop_duplicates(inplace=True)

df.shape

df.isna().sum()

df['price'] = df.groupby(['city', 'room_type'])['price'].transform(lambda x: x.fillna(x.mean()))

"""> Why Group-wise Mean Imputation



Instead of filling missing prices with the overall dataset mean or median,
we used the **mean price within each city-room_type group**.  
This approach ensures:
1. The imputed values are context-specific (e.g., a missing price for a "Private room" in Paris gets filled using other "Private rooms" in Paris).
2. It avoids unrealistic global averages (e.g., luxury listings inflating prices for budget listings in other cities).
3. It maintains the natural price variation between cities and property types.

"""

df['reviews_per_month'].fillna(df['reviews_per_month'].median(), inplace=True)

upper_price = df['price'].quantile(0.99)
df = df[df['price'] <= upper_price]

df['price'].describe()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(df['price'], bins=50, color='royalblue', edgecolor='black')
plt.title('Distribution of Airbnb Listing Prices')
plt.xlabel('Price ($)')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)
plt.show()

# HYPOTHESIS TEST: Are prices normally distributed? (Anderson-Darling)
from scipy.stats import anderson

print("=== PRICE DISTRIBUTION NORMALITY TEST: ANDERSON-DARLING ===")

prices_clean = df['price'].dropna()
sample_prices = prices_clean.sample(5000, random_state=42) if len(prices_clean) > 5000 else prices_clean

result = anderson(sample_prices, dist='norm')
print(f"Anderson-Darling statistic: {result.statistic:.4f}")

for critical_value, significance in zip(result.critical_values, result.significance_level):
    if result.statistic > critical_value:
        print(f"  At {significance:.1f}% significance: Reject null hypothesis (NOT normal)")
    else:
        print(f"  At {significance:.1f}% significance: Cannot reject null hypothesis (Normal)")

"""‚ÄúThe price data is NOT normally distributed.‚Äù

‚ÄúAnderson-Darling test strongly rejects normality for price (stat=764.06; p<0.01). All subsequent hypothesis tests use non-parametric methods.‚Äù


"""

#Cap price at 99th percentile for analysis
cap = df['price'].quantile(0.99)
df['price_capped'] = df['price'].clip(upper=cap)

from scipy.stats import kruskal
city_groups = [group['price'].dropna() for name, group in df.groupby('city')]
stat, p = kruskal(*city_groups)
print(f"Kruskal-Wallis p-value for city groups: {p:.4f}")

from scipy.stats import mannwhitneyu
single = df[df['calculated_host_listings_count'] == 1]['price']
multi = df[df['calculated_host_listings_count'] > 1]['price']
stat, p = mannwhitneyu(single, multi)
print(f"Mann-Whitney U p-value for host type: {p:.4f}")

df = df[df['minimum_nights'] <= 30]
df.shape

df['city'].value_counts()

df['city'].unique()

# HYPOTHESIS TEST 1: City Effects on Price
print("=== CITY EFFECTS ON PRICE ===")

from scipy.stats import kruskal

df_city_price = df[['city', 'price']].dropna()
city_groups = [group['price'] for name, group in df_city_price.groupby('city')]

# Kruskal-Wallis test (non-parametric ANOVA)
stat, p_city = kruskal(*city_groups)
CITY_SIGNIFICANT = p_city < 0.05

print(f"Kruskal-Wallis statistic: {stat:.4f}")
print(f"P-value: {p_city:.2e}")
print(f"Result: {'SIGNIFICANT' if CITY_SIGNIFICANT else 'NOT SIGNIFICANT'}")

if p_city < 0.05:
    print("‚úÖ SIGNIFICANT: Cities have different price distributions")

    city_stats = df_city_price.groupby('city')['price'].agg(['count', 'median', 'std']).round(2)
    city_stats = city_stats.sort_values('median', ascending=False)
    print("\nCity Rankings by Median Price:")
    print(city_stats)

df['room_type'].unique()

# HYPOTHESIS TEST 2: Room Type Effects on Price
print("=== ROOM TYPE EFFECTS ON PRICE ===")

df_room = df[['room_type', 'price']].dropna()
room_groups = [group['price'] for name, group in df_room.groupby('room_type')]

# Kruskal-Wallis test (non-parametric ANOVA)
stat, p_room = kruskal(*room_groups)
ROOM_TYPE_SIGNIFICANT = p_room < 0.05

print(f"Kruskal-Wallis statistic: {stat:.4f}")
print(f"P-value: {p_room:.2e}")
print(f"Result: {'SIGNIFICANT' if ROOM_TYPE_SIGNIFICANT else 'NOT SIGNIFICANT'}")

if p_room < 0.05:
    print("‚úÖ SIGNIFICANT: Room types have different price distributions")

    room_stats = df_room.groupby('room_type')['price'].agg(['count', 'median', 'std']).round(2)
    room_stats = room_stats.sort_values('median', ascending=False)
    print("\nRoom Type Rankings by Median Price:")
    print(room_stats)

# HYPOTHESIS TEST 3: Host Characteristics Impact on Price
print("=== HOST CHARACTERISTICS IMPACT ON PRICE ===")


single_hosts = df[df['calculated_host_listings_count'] == 1]['price'].dropna()
multi_hosts = df[df['calculated_host_listings_count'] > 1]['price'].dropna()

# Mann-Whitney U test (non-parametric two-sample test)
stat, p_host = mannwhitneyu(single_hosts, multi_hosts, alternative='two-sided')
HOST_SIGNIFICANT = p_host < 0.05

print(f"Mann-Whitney U statistic: {stat:.4f}")
print(f"P-value: {p_host:.2e}")
print(f"Result: {'SIGNIFICANT' if HOST_SIGNIFICANT else 'NOT SIGNIFICANT'}")

if p_host < 0.05:
    print("‚úÖ SIGNIFICANT: Host types price differently")
    print(f"Single-host median price: ${single_hosts.median():.0f}")
    print(f"Multi-host median price: ${multi_hosts.median():.0f}")

# HYPOTHESIS TEST 4: Reviews Impact on Price
print("=== REVIEWS IMPACT ON PRICE ===")

df_reviews = df[['number_of_reviews', 'price']].dropna()

# Spearman correlation (non-parametric correlation)
corr, p_reviews = spearmanr(df_reviews['number_of_reviews'], df_reviews['price'])
REVIEWS_SIGNIFICANT = p_reviews < 0.05

print(f"Spearman correlation coefficient: {corr:.4f}")
print(f"P-value: {p_reviews:.2e}")
print(f"Result: {'SIGNIFICANT' if REVIEWS_SIGNIFICANT else 'NOT SIGNIFICANT'}")

if p_reviews < 0.05:
    correlation_direction = "Positive" if corr > 0 else "Negative"
    print(f"‚úÖ SIGNIFICANT: {correlation_direction} correlation between reviews and price")

print(df['neighbourhood'].nunique())
print(df['neighbourhood'].value_counts().head())

from scipy.stats import kruskal

# List of price values by neighbourhood
groups = [group['price'].values for name, group in df.groupby('neighbourhood')]


stat, p = kruskal(*groups)
NEIGHBOURHOOD_SIGNIFICANT = p_reviews < 0.05

print(f"Kruskal-Wallis H-statistic: {stat:.4f}, p-value: {p:.4g}")
print(f"Result: {'SIGNIFICANT' if NEIGHBOURHOOD_SIGNIFICANT else 'NOT SIGNIFICANT'}")

if p < 0.05:
    print("Neighbourhood has a statistically significant effect on price (p < 0.05). Consider keeping it as a feature.")
else:
    print("No significant effect of neighbourhood on price (p ‚â• 0.05). Dropping it is reasonable.")

neigh_freq_map = df['neighbourhood'].value_counts(normalize=True)
df['neighbourhood_freq_enc'] = df['neighbourhood'].map(neigh_freq_map)

joblib.dump(neigh_freq_map, 'neigh_freq_map.pkl')

room_type_map = {'room_type' : {
    'Entire home/apt': 0,
    'Private room': 1,
    'Shared room': 2,
    'Hotel room': 3
}}
df.replace(room_type_map, inplace=True)
df['room_type'].unique()

city_label_map = {'city':{
    'Paris': 0,
    'Rome': 1,
    'Amsterdam': 2,
    'Berlin': 3,
    'Prague': 4,
    'Barcelona': 5,
    'Budapest': 6,
    'Vienna': 7,
    'Athens': 8,
    'Istanbul': 9,
    'Dublin': 10,
    'Oslo': 11,
    'Stockholm': 12,
    'Copenhagen': 13,
    'Brussels': 14
}}
df.replace(city_label_map, inplace=True)
df['city'].unique()

df['price'] = df['price'].replace('[\$,]', '', regex=True).astype(float)

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Correlation Between Features")
plt.show()

"""#Statistical Insights Summary"""

# STATISTICAL INSIGHTS SUMMARY
print("=== STATISTICAL TESTING RESULTS SUMMARY ===\n")

test_results = [
    ("City Effects on Price", CITY_SIGNIFICANT),
    ("Room Type Effects on Price", ROOM_TYPE_SIGNIFICANT),
    ("Reviews Impact on Price", REVIEWS_SIGNIFICANT),
    ("Host Characteristics Impact on Price", HOST_SIGNIFICANT),
    ("Neighbourhood Effects on Price", NEIGHBOURHOOD_SIGNIFICANT)
]

significant_features = [name for name, significant in test_results if significant]

if significant_features:
    print("‚úÖ Statistically significant features that justify inclusion in the model:")
    for feature in significant_features:
        print(f" - {feature}")
else:
    print("‚ùå No statistically significant features detected for modeling at p < 0.05 level.")

"""#Splitting the Data"""

#Prepare features and target

X = df.drop(['price'], axis=1)
y = df['price']

# CHECK FOR POTENTIAL DATA LEAKAGE
print("=== FEATURE LEAKAGE DETECTION ===")
print(f"Total features in X: {len(X.columns)}")
print(f"Target variable shape: {y.shape}")

# Check for price-related column names
price_keywords = ['price', 'cost', 'fee', 'total', 'amount', 'revenue', 'income', 'earnings']
suspicious_columns = [col for col in X.columns if any(keyword in col.lower() for keyword in price_keywords)]

print(f"\nSuspicious price-related columns in features:")
if suspicious_columns:
    for col in suspicious_columns:
        print(f"  - {col}")
    print("\nPOTENTIAL DATA LEAKAGE DETECTED!")
else:
    print("  None found - Good!")

# Check for columns with perfect correlation to target
print(f"\nChecking correlations with target variable...")
correlations = []
for col in X.select_dtypes(include=['int64', 'float64']).columns:
    try:
        corr = X[col].corr(y)
        if abs(corr) > 0.95:  # Very high correlation
            correlations.append((col, corr))
    except:
        pass

if correlations:
    print("Features with suspiciously high correlation to price:")
    for col, corr in sorted(correlations, key=lambda x: abs(x[1]), reverse=True):
        print(f"  - {col}: {corr:.4f}")
else:
    print("  No suspiciously high correlations found")

print(f"\nFeature columns: {list(X.columns)}")

# PREPARE CLEAN FEATURES AND TARGET (NO DATA LEAKAGE)
print("=== PREPARING FEATURES AND TARGET ===")

# Remove leaky features completely
print(f"Removing leaky features: {suspicious_columns}")

# Create clean feature set
X = df.drop(['price'] + suspicious_columns, axis=1, errors='ignore')
y = df['price']

# Remove the original 'neighbourhood' column as it has been frequency encoded
X = X.drop('neighbourhood', axis=1)

# Apply log transform to TARGET only (not as a feature)
y_log = np.log(y)

print(f"Clean features shape: {X.shape}")
print(f"Original target shape: {y.shape}")
print(f"Log-transformed target shape: {y_log.shape}")
print(f"Final feature columns: {list(X.columns)}")

from sklearn.model_selection import train_test_split

X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y_log,
                                                           test_size=0.2,
                                                           random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train_raw)
X_test  = scaler.transform(X_test_raw)

y_train_log = np.log1p(y_train)
y_test_log = np.log1p(y_test)

"""#Testing the Models"""

from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Define models
models = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "LightGbm": LGBMRegressor(n_estimators=100,random_state=42,verbose=-1)
}

# Train and evaluate
results = {}
model_scores={'Model':[],'RMSE':[],'R¬≤':[]}

for name, model in models.items():
    model.fit(X_train, y_train_log)
    y_pred_log = model.predict(X_test)
    y_pred = np.expm1(y_pred_log)   # <-- THIS LINE IS ESSENTIAL
    rmse = np.sqrt(mean_squared_error(np.expm1(y_test_log), y_pred))
    r2 = r2_score(np.expm1(y_test_log), y_pred)
    results[name] = {"RMSE": rmse, "R¬≤": r2}
    model_scores['Model'].append(name)
    model_scores['RMSE'].append(rmse)
    model_scores['R¬≤'].append(r2)



# Show results
pd.DataFrame(results).T.sort_values(by="RMSE")

import seaborn as sns
import matplotlib.pyplot as plt

df_scores = pd.DataFrame(model_scores)

# Bar plot for RMSE
plt.figure(figsize=(8,4))
sns.barplot(x='Model', y='RMSE', data=df_scores, palette='coolwarm')
plt.title('Model RMSE Comparison')
plt.show()

# Bar plot for R¬≤
plt.figure(figsize=(8,4))
sns.barplot(x='Model', y='R¬≤', data=df_scores, palette='crest')
plt.title('Model R¬≤ Score Comparison')
plt.show()

"""## Log-Transform Workflow

1. **Original price is kept for exploration and reporting.**
2. **Train-Test Split is performed on the original price.**
3. **Target is log-transformed (y_train_log = np.log1p(y_train)) only after splitting, for modeling.**
4. **After prediction, log-transformed predictions are converted back to euros (y_pred = np.expm1(y_pred_log)).**
5. **All metrics, plots, and business interpretations are performed on the euros scale, not log scale.**

#Model Training with LightGBM

Based on model evaluation, the Random Forest Regressor achieved the best overall performance with the lowest RMSE and highest R¬≤ score, making it the most suitable model for predicting Airbnb prices.

However, I also explored LightGBM due to its ability to handle large datasets efficiently. LightGBM offers faster training, better scalability, and advanced boosting techniques that often yield high accuracy. It also natively handles missing values and categorical features, making it a strong alternative for production deployment.

Linear and Ridge Regression, on the other hand, performed poorly (R¬≤ ‚âà 0.10), indicating that they failed to capture the complex, non-linear relationships present in the data‚Äîmaking them unsuitable for this task.
"""

from lightgbm import LGBMRegressor

model = LGBMRegressor(
    n_estimators=100,
    random_state=42,
    verbose=-1
)

model.fit(X_train, y_train_log)
y_pred_log = model.predict(X_test)  # Predictions are in log scale
y_pred = np.expm1(y_pred_log)  # Convert to original price scale

# Evaluation - both on original price scale
rmse = np.sqrt(mean_squared_error(np.expm1(y_test_log), y_pred))
r2 = r2_score(np.expm1(y_test_log), y_pred)


print(f"RMSE: {rmse}")
print(f"R¬≤ Score: {r2}")

"""##Hyperparameter Tuning
####Why Hyperparameter Tuning?
Hyperparameter tuning is the process of finding the best settings for a machine learning model to maximize its performance. In this project, tuning helps improve prediction accuracy, prevent overfitting, and make the model more efficient. We use RandomizedSearchCV to test different combinations of hyperparameters for our LightGBM model, selecting the set that provides the lowest prediction error and highest R¬≤ score for Airbnb price prediction.
"""

from sklearn.model_selection import RandomizedSearchCV

param_grid = {
    'num_leaves': [31, 50, 70],
    'max_depth': [-1, 10, 20],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 500],
    'min_child_samples': [20, 40]
}

lgbm_rs = LGBMRegressor(n_estimators=100,random_state=42,verbose=-1)

random_search_lgbm = RandomizedSearchCV(
    estimator=lgbm_rs,
    param_distributions=param_grid,
    n_iter=30,
    scoring='neg_mean_squared_error',
    cv=5,
    verbose=1,
    n_jobs=-1
)

random_search_lgbm.fit(X_train, y_train_log)
best_lgbm = random_search_lgbm.best_estimator_



# Save model and scaler
import joblib
joblib.dump(best_lgbm, 'lightgbm_airbnb_model.pkl')
joblib.dump(scaler, 'feature_scaler.pkl')

# Predict with best model
y_pred_best_lgbm_log = best_lgbm.predict(X_test)
y_pred_best_lgbm = np.expm1(y_pred_best_lgbm_log)
rmse_best = np.sqrt(mean_squared_error(np.expm1(y_test_log), y_pred_best_lgbm))
r2_best = r2_score(np.expm1(y_test_log), y_pred_best_lgbm)
print(f"Best LightGBM RMSE: {rmse_best}")
print(f"Best LightGBM R¬≤: {r2_best}")

import matplotlib.pyplot as plt
import seaborn as sns

feature_importance = pd.Series(best_lgbm.feature_importances_, index=X.columns).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importance[:15], y=feature_importance.index[:15])
plt.title("Top 15 LightGBM Feature Importances")
plt.tight_layout()
plt.show()

"""###Final Evaluation"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

y_pred_log = random_search_lgbm.best_estimator_.predict(X_test)
y_pred = np.expm1(y_pred_log)
rmse = np.sqrt(mean_squared_error(np.expm1(y_test_log), y_pred))  # FIXED!
r2 = r2_score(np.expm1(y_test_log), y_pred)  # FIXED!


print(f"RMSE: {rmse:.2f}")
print(f"R¬≤ Score: {r2:.4f}")

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score

# Back-transform to original price scale
y_test_original = np.expm1(y_test_log)
y_pred_original = np.expm1(y_pred_log)

# Clamp extreme values for both actual & predicted to avoid plot distortion
limit = np.percentile(y_test_original, 99)
y_test_original = np.clip(y_test_original, 0, limit)
y_pred_original = np.clip(y_pred_original, 0, limit)

# Calculate metrics
rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))
r2 = r2_score(y_test_original, y_pred_original)

# Calculate absolute errors for coloring
errors = np.abs(y_test_original - y_pred_original)
# These errors are used as the color scale in the scatter plot, making it easy to see where the model predicts well (dark blue) vs poorly (yellow).

# Plot
plt.figure(figsize=(8, 6))
scatter = plt.scatter(
    y_test_original, y_pred_original,
    c=errors, cmap='viridis', alpha=0.5, s=20, edgecolor='none'
)

# Colorbar for error scale
cbar = plt.colorbar(scatter)
cbar.set_label('Absolute Error')

# Perfect prediction line
plt.plot(
    [y_test_original.min(), y_test_original.max()],
    [y_test_original.min(), y_test_original.max()],
    'r--', lw=2
)

# Labels & title
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Actual vs Predicted Price (LightGBM)")

# Annotate RMSE & R¬≤ inside plot
plt.text(
    0.05, 0.95, f"RMSE={rmse:.2f}\nR¬≤={r2:.3f}",
    transform=plt.gca().transAxes,
    fontsize=12, verticalalignment='top',
    bbox=dict(facecolor='white', alpha=0.6, edgecolor='none')
)

plt.grid(True, linestyle='--', alpha=0.7)
plt.axis('equal')  # Match scaling of axes
plt.tight_layout()
plt.show()

"""**Why this plot is useful?**

- It provides a visual check on model performance.
- The color scale highlights which price ranges or listings the model struggles with.
- It complements numeric metrics like RMSE and R¬≤, helping detect patterns
  such as underestimation of high prices or overestimation of low prices.
"""

# STATISTICAL VALIDATION OF LIGHTGBM PERFORMANCE
print(f"WHY LIGHTGBM ACHIEVES R¬≤‚âà{r2:.2f}")
print("‚Ä¢ Prices are highly non-normal and skewed (Anderson-Darling p<0.01)")
print("‚Ä¢ Non-parametric tests confirm:")
print("  ‚Äì City differences (p<0.01)")
print("  ‚Äì Room type differences (p<0.01)")
print("  ‚Äì Host characteristics effects (p<0.05)")
print("‚Ä¢ Spearman correlation shows reviews mildly predict price (p<0.05)")
print("\nLightGBM‚Äôs tree-based splits excel at capturing these non-linear, categorical, and skewed relationships.")
print(f"Your model‚Äôs R¬≤‚âà{r2:.2f} validates these statistically significant feature impacts.")

"""Scatter Plot helps assess if the model is systematically under- or over-predicting.

If your predictions are perfect, points would lie on the red diagonal line.

The more scattered the points, the lower the model's accuracy.
"""

import folium

# Center the map
map = folium.Map(location=[df.latitude.mean(), df.longitude.mean()], zoom_start=12)

for _, row in df.sample(500).iterrows():  # sample for performance
    folium.CircleMarker(
        location=[row.latitude, row.longitude],
        radius=3,
        color='blue',
        fill=True,
        fill_opacity=0.6,
        popup=f"${row.price}"
    ).add_to(map)

map.save("price_map.html")

print("Training features:", list(X.columns))
print("Scaler feature names:", scaler.feature_names_in_)

"""This project aims to predict Airbnb listing prices using machine learning. We trained multiple regression models (including Random Forest and LightGBM) on cleaned listing data, using features such as location, room type, and review metrics. Price was used as the target variable, and models were evaluated using RMSE and R¬≤ metrics to ensure accuracy"""